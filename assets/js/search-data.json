{
  
    
        "post0": {
            "title": "계층적 군집분석",
            "content": "som, DBscan, k-means . library(&#39;tidyverse&#39;) library(kohonen) #som library(gclus) #wine data library(MASS) library(cowplot) library(gridExtra) #grid arrange에 사용 . SOM . data(wine) head(wine) . A data.frame: 6 × 14 ClassAlcoholMalicAshAlcalinityMagnesiumPhenolsFlavanoidsNonflavanoidProanthocyaninsIntensityHueOD280Proline . &lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt; . 11 | 14.23 | 1.71 | 2.43 | 15.6 | 127 | 2.80 | 3.06 | 0.28 | 2.29 | 5.64 | 1.04 | 3.92 | 1065 | . 21 | 13.20 | 1.78 | 2.14 | 11.2 | 100 | 2.65 | 2.76 | 0.26 | 1.28 | 4.38 | 1.05 | 3.40 | 1050 | . 31 | 13.16 | 2.36 | 2.67 | 18.6 | 101 | 2.80 | 3.24 | 0.30 | 2.81 | 5.68 | 1.03 | 3.17 | 1185 | . 41 | 14.37 | 1.95 | 2.50 | 16.8 | 113 | 3.85 | 3.49 | 0.24 | 2.18 | 7.80 | 0.86 | 3.45 | 1480 | . 51 | 13.24 | 2.59 | 2.87 | 21.0 | 118 | 2.80 | 2.69 | 0.39 | 1.82 | 4.32 | 1.04 | 2.93 | 735 | . 61 | 14.20 | 1.76 | 2.45 | 15.2 | 112 | 3.27 | 3.39 | 0.34 | 1.97 | 6.75 | 1.05 | 2.85 | 1450 | . wine.sc &lt;- scale(wine) #표준화 . set.seed(7) wine.som &lt;- som(wine.sc, grid = somgrid(5, 4, topo = &quot;hexagonal&quot;)) . grid &lt;- 경쟁층 grid 어떻게 나타낼지 . summary(wine.som) . SOM of size 5x4 with a hexagonal topology and a bubble neighbourhood function. The number of data layers is 1. Distance measure(s) used: sumofsquares. Training data included: 178 objects. Mean distance to the closest unit in the map: 3.68. . attributes(wine.som) . $names &lt;ol class=list-inline&gt;&#39;data&#39; | &#39;unit.classif&#39; | &#39;distances&#39; | &#39;grid&#39; | &#39;codes&#39; | &#39;changes&#39; | &#39;alpha&#39; | &#39;radius&#39; | &#39;na.rows&#39; | &#39;user.weights&#39; | &#39;distance.weights&#39; | &#39;whatmap&#39; | &#39;maxNA.fraction&#39; | &#39;dist.fcts&#39; | &lt;/ol&gt; $class &#39;kohonen&#39; 뭐 들어있나 알려줌 . nunits(wine.som) . 20 wine.som$distances %&gt;% head #거리 나타냄 . &lt;ol class=list-inline&gt;3.62335093060936 | 3.78796592791914 | 4.04197458392212 | 4.69655798146311 | 3.42598912797278 | 1.57390248634172 | &lt;/ol&gt; wine.som$unit.classif . &lt;ol class=list-inline&gt;5 | 9 | 4 | 4 | 2 | 4 | 9 | 3 | 5 | 5 | 4 | 9 | 9 | 5 | 5 | 4 | 4 | 4 | 4 | 10 | 5 | 10 | 9 | 9 | 3 | 2 | 9 | 9 | 3 | 9 | 4 | 4 | 3 | 3 | 3 | 9 | 3 | 9 | 9 | 5 | 5 | 10 | 5 | 10 | 5 | 10 | 5 | 5 | 4 | 4 | 5 | 4 | 5 | 4 | 5 | 4 | 5 | 4 | 4 | 12 | 18 | 18 | 12 | 7 | 17 | 7 | 7 | 11 | 18 | 8 | 13 | 2 | 11 | 2 | 7 | 12 | 12 | 13 | 8 | 6 | 7 | 7 | 16 | 19 | 1 | 11 | 17 | 16 | 16 | 16 | 17 | 17 | 17 | 7 | 7 | 8 | 13 | 7 | 7 | 1 | 12 | 11 | 6 | 11 | 11 | 17 | 11 | 17 | 11 | 1 | 1 | 6 | 16 | 16 | 16 | 16 | 11 | 11 | 18 | 6 | 1 | 2 | 6 | 6 | 1 | 6 | 6 | 16 | 6 | 6 | 13 | 14 | 14 | 14 | 18 | 18 | 19 | 19 | 20 | 19 | 19 | 14 | 19 | 19 | 14 | 14 | 20 | 20 | 20 | 15 | 15 | 15 | 15 | 20 | 14 | 20 | 20 | 19 | 15 | 15 | 20 | 19 | 19 | 14 | 20 | 20 | 15 | 20 | 15 | 15 | 14 | 20 | 20 | 20 | 20 | 15 | 15 | 20 | &lt;/ol&gt; 5 * 4 라 20까지 숫자 나옴 . plot(wine.som, main=&quot;Wine data&quot;) #노옵션 그림 . 1,1 노드에서의 결과 1번째 이런식 . par(mfrow=c(1,3)) plot(wine.som, type=&quot;counts&quot;, main=&quot;wine data: counts&quot;) plot(wine.som, type=&quot;quality&quot;, main=&quot;wine data: mapping quality&quot;) plot(wine.som, type=&quot;mapping&quot;, col = wine.som$unit.classif, pch = wine.som$unit.classif, main=&quot;mapping plot&quot;) graphics.off() . 1)그림 count 사용해서 빨간색 진한쪽은 관측값이 적게 들어있는 것 연한쪽은 많은 2)그림 가운데 평균 좋은 애들은 노랑 아닌애들은 빨강으로 3)그림 그게 어떤식으로 분포하는지 그림으로 표현 . DB scan . library(dbscan) #dbscan, knndist library(cluster) library(ggplot2) . 데이터 분포 . set.seed(1004) x &lt;- c(rnorm(50,1,0.05), rnorm(300,2,0.4), rnorm(100,1,0.2)) y &lt;- c(rnorm(50,0.5,0.05), rnorm(300,2,0.4), rnorm(100,-1,0.2)) dt &lt;- data.frame(x=x, y=y) ggplot(dt, aes(x,y))+ geom_point(col=&#39;steelblue&#39;)+ xlab(&quot;&quot;)+ylab(&quot;&quot;)+ theme_bw() . plot(dt, pch=16, col=&#39;steelblue&#39;) #ggplot 어려우면 그냥 그려도 됨 . kNNdistplot(dt, k = 5) #가장 가까운 5번째 관측값까지의 거리 #kNNdist(dt, k = 5) head(kNNdist(dt, k = 5),15) abline(h = seq(0.2,0.4,0.05), col = &quot;red&quot;, lty=2) abline(h=0.1) kNNdistplot(dt, k = 10) . &lt;ol class=list-inline&gt;0.0229799071909654 | 0.0527603088956091 | 0.0399574649903798 | 0.0253976801040939 | 0.0247549341238805 | 0.0347093275330297 | 0.039348122697994 | 0.0277180280364887 | 0.0189902832418738 | 0.0528103292387965 | 0.056599441272081 | 0.0340819947062685 | 0.0321563132416409 | 0.0569875888535442 | 0.0877619963066104 | &lt;/ol&gt; 그림 보면 eps=0.2정도 해주면 대부분(400개) 가까이가 범위 안으로 들어감 . eps &lt;- 0.3 res &lt;- dbscan(dt, eps = eps , minPts = 5) str(res) res . List of 3 $ cluster: int [1:450] 1 1 1 1 1 1 1 1 1 1 ... $ eps : num 0.3 $ minPts : num 5 - attr(*, &#34;class&#34;)= chr [1:2] &#34;dbscan_fast&#34; &#34;dbscan&#34; . DBSCAN clustering for 450 objects. Parameters: eps = 0.3, minPts = 5 The clustering contains 3 cluster(s) and 3 noise points. 0 1 2 3 3 50 297 100 Available fields: cluster, eps, minPts . ggplot(dt, aes(x,y, col=as.factor(res$cluster)))+ geom_point()+ xlab(&quot;&quot;)+ylab(&quot;&quot;)+ggtitle(paste0(&#39;BDscan : epsilon = &#39;, eps))+labs(col = &quot;cluster&quot;)+ theme_bw() . 매우 원하는데로 그림 나옴 . 다른 eps 들도 해봄 . eps &#46384;&#46972; &#44536;&#47532;&#44592; . eps &lt;- 0.2 res1 &lt;- dbscan(dt, eps = eps , minPts = 5) p1 &lt;- ggplot(dt, aes(x,y, col=as.factor(res1$cluster)))+ geom_point()+ xlab(&quot;&quot;)+ylab(&quot;&quot;)+ggtitle(paste0(&#39;BDscan : epsilon = &#39;, eps))+labs(col = &quot;cluster&quot;)+ theme_bw() eps &lt;- 0.3 res2 &lt;- dbscan(dt, eps = eps , minPts = 5) p2 &lt;- ggplot(dt, aes(x,y, col=as.factor(res2$cluster)))+ geom_point()+ xlab(&quot;&quot;)+ylab(&quot;&quot;)+ggtitle(paste0(&#39;BDscan : epsilon = &#39;, eps))+labs(col = &quot;cluster&quot;)+ theme_bw() eps &lt;- 0.7 res3 &lt;- dbscan(dt, eps = eps , minPts = 5) p3 &lt;- ggplot(dt, aes(x,y, col=as.factor(res3$cluster)))+ geom_point()+ xlab(&quot;&quot;)+ylab(&quot;&quot;)+ggtitle(paste0(&#39;BDscan : epsilon = &#39;, eps))+labs(col = &quot;cluster&quot;)+ theme_bw() grid.arrange(p1, p2, p3, nrow = 1) . eps 0.2였으면 몇개 짤렸음 . &#46608;&#54620; m&#44050;&#50640; &#46384;&#46972;&#49436;&#46020; &#45804;&#46972;&#51664; . m 값 = minimum point . m &lt;- 3 res1 &lt;- dbscan(dt, eps = 0.3 , minPts = m) p1 &lt;- ggplot(dt, aes(x,y, col=as.factor(res1$cluster)))+ geom_point()+ xlab(&quot;&quot;)+ylab(&quot;&quot;)+ggtitle(paste0(&#39;BDscan : minPts = &#39;, m))+ labs(col = &quot;cluster&quot;)+ theme_bw() m &lt;- 5 res2 &lt;- dbscan(dt, eps = 0.3 , minPts = m) p2 &lt;- ggplot(dt, aes(x,y, col=as.factor(res2$cluster)))+ geom_point()+ xlab(&quot;&quot;)+ylab(&quot;&quot;)+ggtitle(paste0(&#39;BDscan : minPts = &#39;, m))+ labs(col = &quot;cluster&quot;)+ theme_bw() m &lt;- 10 res3 &lt;- dbscan(dt, eps = 0.4 , minPts = m) p3 &lt;- ggplot(dt, aes(x,y, col=as.factor(res3$cluster)))+ geom_point()+ xlab(&quot;&quot;)+ylab(&quot;&quot;)+ggtitle(paste0(&#39;BDscan : minPts = &#39;, m))+ labs(col = &quot;cluster&quot;)+ theme_bw() grid.arrange(p1, p2, p3, nrow = 1) . m값을 키우고 eps 줄여도 됨 상호 배타적으로 . k-means&#47196; &#44536;&#47532;&#44592; . res_k &lt;- kmeans(dt, center=3, nstart = 20) ggplot(dt, aes(x,y, col=as.factor(res_k$cluster)))+geom_point()+ xlab(&quot;&quot;)+ylab(&quot;&quot;)+ggtitle(&#39;Kmeans&#39;)+ labs(col = &quot;cluster&quot;)+ theme_bw() . DB scan이 더 나은듯 . &#49352;&#47196;&#50868; &#45936;&#51060;&#53552;&#47196; &#54644;&#48372;&#44592; . data(ruspini) head(ruspini) . A data.frame: 6 × 2 xy . &lt;int&gt;&lt;int&gt; . 1 4 | 53 | . 2 5 | 63 | . 310 | 59 | . 4 9 | 77 | . 513 | 49 | . 613 | 69 | . 데이터 분포 . ggplot(ruspini, aes(x,y))+geom_point(col=&#39;steelblue&#39;)+ xlab(&quot;&quot;)+ylab(&quot;&quot;)+ theme_bw() . kNNdistplot(ruspini, k = 5) abline(h = 15:20, col = &quot;red&quot;, lty=2) . DBscan . res &lt;- dbscan(ruspini, eps = 15, minPts = 5) res ggplot(ruspini, aes(x,y, col=as.factor(res$cluster)))+geom_point()+ xlab(&quot;&quot;)+ylab(&quot;&quot;)+coord_fixed()+labs(col = &quot;cluster&quot;)+ theme_bw() . DBSCAN clustering for 75 objects. Parameters: eps = 15, minPts = 5 The clustering contains 4 cluster(s) and 3 noise points. 0 1 2 3 4 3 20 23 14 15 Available fields: cluster, eps, minPts . K-means . res_k &lt;- kmeans(ruspini,centers =4) ruspini$cluster_k &lt;- as.factor(res_k$cluster) ggplot(ruspini, aes(x,y, col=cluster_k))+geom_point()+ xlab(&quot;&quot;)+ylab(&quot;&quot;)+coord_fixed()+labs(col = &quot;cluster&quot;)+ theme_bw() . 이건 k-means가 결과 더 좋은듯? . &#51116;&#48140;&#45716; &#54805;&#53468;&#51032; &#45936;&#51060;&#53552; . set.seed(-1) get.sample &lt;- function(n=1000, p=0.7){ x1 &lt;- rnorm(n) y1 &lt;- rnorm(n) r2 &lt;- 7 + rnorm(n) t2 &lt;- runif(n,0,2*pi) x2 &lt;- r2*cos(t2) y2 &lt;- r2*sin(t2) r &lt;- runif(n)&gt;p x &lt;- ifelse(r,x1,x2) y &lt;- ifelse(r, y1, y2) d &lt;- data.frame(x=x, y=y) d } dt &lt;- get.sample() ggplot(dt, aes(x,y))+geom_point(col=&#39;steelblue&#39;)+ xlab(&quot;&quot;)+ylab(&quot;&quot;)+ theme_bw() . DBScan vs. kmeans . kNNdistplot(dt, k = 5) abline(h = seq(1,1.5,0.1), col = &quot;red&quot;, lty=2) res_db &lt;- dbscan(dt, eps = 1, minPts = 5) res_kmeans &lt;- kmeans(dt,centers =2) p1 &lt;- ggplot(dt, aes(x,y, col=as.factor(res_db$cluster)))+geom_point()+ xlab(&quot;&quot;)+ylab(&quot;&quot;)+ggtitle(&#39;DB scan&#39;)+ labs(col = &quot;cluster&quot;)+ theme_bw() p2 &lt;- ggplot(dt, aes(x,y, col=as.factor(res_kmeans$cluster)))+geom_point()+ xlab(&quot;&quot;)+ylab(&quot;&quot;)+ggtitle(&#39;K menas&#39;)+ labs(col = &quot;cluster&quot;)+ theme_bw() grid.arrange(p1, p2, nrow = 1) . 절대적으로 DB scan이 좋음 그러나 현실에서는 이런형태의 데이터인지 알 수가 없음 분석하기 전에 . new data . set.seed(12) x1 &lt;- runif(300,-1,1) y1 &lt;- 2*x1^2-1.5+ rnorm(300,0,0.2) x2 &lt;- runif(300,-2,0) y2 &lt;- -2*(x2+1)^2 + 1.5 + rnorm(300,0,0.2) dt1 &lt;- data.frame(x = c(x1,x2), y = c(y1,y2)) ggplot(dt1, aes(x,y))+geom_point(col=&#39;steelblue&#39;)+ xlab(&quot;&quot;)+ylab(&quot;&quot;)+ theme_bw() . DBScan vs. kmeans . kNNdistplot(dt1, k = 5) abline(h = 0.2, col = &quot;red&quot;, lty=2) res_db &lt;- dbscan(dt1, eps = 0.2, minPts = 5) res_kmeans &lt;- kmeans(dt1,centers =2) p1 &lt;- ggplot(dt1, aes(x,y, col=as.factor(res_db$cluster)))+geom_point()+ xlab(&quot;&quot;)+ylab(&quot;&quot;)+ggtitle(&#39;DB scan&#39;)+ labs(col = &quot;cluster&quot;)+ theme_bw() p2 &lt;- ggplot(dt1, aes(x,y, col=as.factor(res_kmeans$cluster)))+geom_point()+ xlab(&quot;&quot;)+ylab(&quot;&quot;)+ggtitle(&#39;K menas&#39;)+ labs(col = &quot;cluster&quot;)+ theme_bw() grid.arrange(p1, p2, nrow = 1) . &#44208;&#47200; . 한 줄 교훈 : 현실에서는 어떤개 더 좋은지 데이터 형태를 알 수가 없으니 다양한 모델을 구현할줄 아는게 중요 그리고 판단의 기준은 주관적이기에 모든 알고리즘에 대해 지식을 가지고 있는게 중요 .",
            "url": "https://jjyun98.github.io/main/2022/07/02/%EA%B3%84%EC%B8%B5%EC%A0%81-%EA%B5%B0%EC%A7%91%EB%B6%84%EC%84%9D-%ED%95%99%EC%8A%B52.html",
            "relUrl": "/2022/07/02/%EA%B3%84%EC%B8%B5%EC%A0%81-%EA%B5%B0%EC%A7%91%EB%B6%84%EC%84%9D-%ED%95%99%EC%8A%B52.html",
            "date": " • Jul 2, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "Title",
            "content": "testfile . 이것은 테스트를 위해 만들어본 자료입니다 . a = [1,2,3] . a . [1, 2, 3] . a[1] . 2 . for i in range(3): print(a[i]) . 1 2 3 .",
            "url": "https://jjyun98.github.io/main/2022/07/02/test.html",
            "relUrl": "/2022/07/02/test.html",
            "date": " • Jul 2, 2022"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://jjyun98.github.io/main/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://jjyun98.github.io/main/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}